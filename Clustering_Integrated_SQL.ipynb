{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text sentences so that punctuation marks, stop words & digits are removed  \n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    processed = re.sub(r\"\\d+\",\"\",normalized)\n",
    "    y = processed.split()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from SQL server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SQL Connector packages.\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance as sci_distance\n",
    "from sklearn import cluster as sk_cluster\n",
    "\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server Native Client 11.0};SERVER=dbsed4432;DATABASE=pera;Trusted_Connection=yes')\n",
    "\n",
    "cursor = cnxn.cursor()\n",
    "data = pd.read_sql_query('SELECT * FROM pera.dbo.eem_l1', cnxn)\n",
    "\n",
    "cursor.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        column_name missing_data  missing_in_percentage\n",
      "0                      HealthSystem            0                    0.0\n",
      "1                            BIC_ID            0                    0.0\n",
      "2                          BIC_Name            0                    0.0\n",
      "3                      Billing_Name            0                    0.0\n",
      "4                       Billing_NPI            0                    0.0\n",
      "5         Billing_NPPES_Parent_Name            0                    0.0\n",
      "6            Billing_NPPES_DBA_Name            0                    0.0\n",
      "7            Billing_NPPES_NPI_Name            0                    0.0\n",
      "8                       Billing_TIN            0                    0.0\n",
      "9             Billing_Taxonomy_Code            0                    0.0\n",
      "10        Billing_Taxonomy_Grouping            0                    0.0\n",
      "11  Billing_Taxonomy_Classification            0                    0.0\n",
      "12  Billing_Taxonomy_Specialization            0                    0.0\n",
      "13                     Billing_Adr1            0                    0.0\n",
      "14                     Billing_Adr2            0                    0.0\n",
      "15                     Billing_City            0                    0.0\n",
      "16                    Billing_State            0                    0.0\n",
      "17                      Billing_Zip            0                    0.0\n",
      "18                       PayTo_Adr1            0                    0.0\n",
      "19                       PayTo_Adr2            0                    0.0\n",
      "20                       PayTo_City            0                    0.0\n",
      "21                      PayTo_State            0                    0.0\n",
      "22                        PayTo_Zip            0                    0.0\n"
     ]
    }
   ],
   "source": [
    "data = data.applymap(str)\n",
    "\n",
    "\n",
    "round((data.isnull().sum()*100)/len(data),2)\n",
    "\n",
    "\n",
    "def miss_data(df):\n",
    "    x = ['column_name','missing_data', 'missing_in_percentage']\n",
    "    missing_data = pd.DataFrame(columns=x)\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        icolumn_name = col\n",
    "        imissing_data = df[col].isnull().sum()\n",
    "        imissing_in_percentage = (df[col].isnull().sum()/df[col].shape[0])*100\n",
    "\n",
    "        missing_data.loc[len(missing_data)] = [icolumn_name, imissing_data, imissing_in_percentage]\n",
    "    print(missing_data)\n",
    "    \n",
    "    \n",
    "miss_data(data)\n",
    "\n",
    "limitPer = len(data) * .80\n",
    "df1 = data.dropna(thresh=limitPer,axis=1)\n",
    "\n",
    "\n",
    "df1=df1.fillna(\"NA\")\n",
    "df1['mergedentity'] = df1[\"BIC_Name\"].str.lower()+ \" \"+df1[\"Billing_Name\"].str.lower()+ df1[\"Billing_NPI\"].str.lower()+ \" \" +df1[\"Billing_NPPES_NPI_Name\"].str.lower()+\" \"+ df1[\"Billing_TIN\"].str.lower()+\" \"+ df1[\"Billing_Adr1\"].str.lower()+\" \" +df1[\"Billing_City\"].str.lower()+df1[\"Billing_State\"].str.lower()+\" \"+df1[\"Billing_City\"].str.lower()+\" \"+df1[\"Billing_Zip\"].str.lower()+\" \"+df1[\"PayTo_Adr1\"].str.lower()+\" \"+df1[\"PayTo_City\"].str.lower()+\" \"+df1[\"PayTo_State\"].str.lower()+\" \"+df1[\"PayTo_Zip\"].str.lower()\n",
    "df1['mergedentity']=df1['mergedentity'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df1, test_size=0)\n",
    "\n",
    "\n",
    "#First column\n",
    "cols = list(train.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "train = train[cols]\n",
    "\n",
    "idea=train.iloc[:,0:1]\n",
    "corpus=[]\n",
    "for index,row in idea.iterrows():\n",
    "    corpus.append(row['mergedentity'])\n",
    "    \n",
    "    \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "#vectorizer.get_feature_names()\n",
    "\n",
    "#print(X.toarray())     \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "transformer = TfidfTransformer(smooth_idf=False)\n",
    "tfidf = transformer.fit_transform(X)\n",
    "\n",
    "\n",
    "y_train=train[\"HealthSystem\"]\n",
    "\n",
    "\n",
    "# Clustering the document with KNN classifier\n",
    "modelknn = KNeighborsClassifier(n_neighbors=5)\n",
    "modelknn.fit(X,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "          Idea    Cluster\n",
      "Ascension  NaN  Ascension\n",
      "Ascension  NaN  Ascension\n",
      "Ascension  NaN  Ascension\n",
      "Ascension  NaN  Ascension\n",
      "Ascension  NaN  Ascension\n",
      "...        ...        ...\n",
      "TriHealth  NaN  TriHealth\n",
      "TriHealth  NaN  TriHealth\n",
      "TriHealth  NaN  TriHealth\n",
      "TriHealth  NaN  TriHealth\n",
      "TriHealth  NaN  TriHealth\n",
      "\n",
      "[4880 rows x 2 columns]\n",
      "\n",
      "\n",
      "Ascension    2358\n",
      "Sutter       1122\n",
      "Tenet         660\n",
      "NYU           347\n",
      "Banner        191\n",
      "Quest         181\n",
      "Genesis        11\n",
      "TriHealth      10\n",
      "Name: Cluster, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#First column\n",
    "cols = list(df1.columns)\n",
    "cols = [cols[-1]] + cols[:-1]\n",
    "df1 = df1[cols]\n",
    "\n",
    "\n",
    "idea=df1.iloc[:,0:1] #Selecting the first column of mergedentity\n",
    "\n",
    "corpus=[]\n",
    "for index,row in idea.iterrows():\n",
    "    corpus.append(row['mergedentity'])\n",
    "    \n",
    "Test2 = vectorizer.transform(corpus)\n",
    "\n",
    "predicted_labels_knn = modelknn.predict(Test2)\n",
    "\n",
    "idea={'Mergeidentity':corpus, 'Cluster':predicted_labels_knn} #Creating dict having doc with the corresponding cluster number.\n",
    "frame=pd.DataFrame(idea,index=[predicted_labels_knn], columns=['Idea','Cluster']) # Converting it into a dataframe.\n",
    "\n",
    "print(\"\\n\")\n",
    "print(frame) #Print the doc with the labeled cluster number.\n",
    "print(\"\\n\")\n",
    "print(frame['Cluster'].value_counts()) #Print the counts of doc belonging to each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Cluster'] = predicted_labels_knn\n",
    "df1.to_excel (r'C:\\Users\\rbalani1\\Desktop\\EEM\\IntegratedModel.xlsx', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload csv to SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "cnxn = pyodbc.connect('DRIVER={SQL Server Native Client 11.0};SERVER=dbsed4432;DATABASE=pera;Trusted_Connection=yes')\n",
    "\n",
    "cursor = cnxn.cursor()\n",
    "\n",
    "df = pd.read_excel(\"C:/Users/rbalani1/Desktop/EEM/IntegratedModel.xlsx\")\n",
    "df = df.applymap(str)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "     cursor.execute(\"INSERT INTO pera.dbo.eem_l1_prediction ([Cluster],[HealthSystem],[BIC_ID],[BIC_Name],[Billing_Name],[Billing_NPI],[Billing_NPPES_NPI_Name],[Billing_TIN],[Billing_Adr1],[Billing_City],[Billing_State],[Billing_Zip],[PayTo_Adr1],[PayTo_City],[PayTo_State],[PayTo_Zip],[Mergedentity]) values(?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\",row['Cluster'], row['HealthSystem'], row['BIC_ID'], row['BIC_Name'], row['Billing_Name'], row['Billing_NPI'], row['Billing_NPPES_NPI_Name'], row['Billing_TIN'], row['Billing_Adr1'], row['Billing_City'], row['Billing_State'],row['Billing_Zip'], row['PayTo_Adr1'], row['PayTo_City'], row['PayTo_State'], row['PayTo_Zip'], row['mergedentity'])\n",
    "\n",
    "\n",
    "cnxn.commit()\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    4880\n",
       "Name: Cluster, dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Cluster'].isin(df1['HealthSystem']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
